{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "metacritic_user_scores",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enriqueav/MetacriticUserscore/blob/master/metacritic_user_scores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "nOHXaHZ2zM2C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "25417c09-906c-48db-d2d7-7115bf8130ba"
      },
      "cell_type": "code",
      "source": [
        "# Install the latest version of TensorFlow\n",
        "!pip install -q -U tensorflow==1.7.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 48.0MB 831kB/s \n",
            "\u001b[K    100% |████████████████████████████████| 3.1MB 8.5MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 890kB 16.7MB/s \n",
            "\u001b[?25h  Building wheel for html5lib (setup.py) ... \u001b[?25ldone\n",
            "\u001b[31mmagenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.7.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1BVI1ZbZ6INM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdbdf0dd-545e-4330-d483-8cbf8d36b741"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow import keras\n",
        "layers = keras.layers\n",
        "\n",
        "# This code was tested with TensorFlow v1.7\n",
        "print(\"You have TensorFlow version\", tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You have TensorFlow version 1.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QkesGscv6-x1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we are going to download the dataset. Originally obtained from [this kaggle dataset](https://www.kaggle.com/dahlia25/metacritic-video-game-comments)"
      ]
    },
    {
      "metadata": {
        "id": "uz2zIJaz6BDK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "18f1dbdf-47ad-4100-f10c-dfb30721ad38"
      },
      "cell_type": "code",
      "source": [
        "!wget -nc https://github.com/enriqueav/MetacriticUserscore/raw/master/metacritic-video-game-comments.zip\n",
        "!unzip -o metacritic-video-game-comments.zip\n",
        "!chmod 777 metacritic*"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-21 10:04:28--  https://github.com/enriqueav/MetacriticUserscore/raw/master/metacritic-video-game-comments.zip\n",
            "Resolving github.com (github.com)... 192.30.255.113, 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/enriqueav/MetacriticUserscore/master/metacritic-video-game-comments.zip [following]\n",
            "--2019-04-21 10:04:29--  https://raw.githubusercontent.com/enriqueav/MetacriticUserscore/master/metacritic-video-game-comments.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 81214297 (77M) [application/zip]\n",
            "Saving to: ‘metacritic-video-game-comments.zip’\n",
            "\n",
            "metacritic-video-ga 100%[===================>]  77.45M   311MB/s    in 0.2s    \n",
            "\n",
            "2019-04-21 10:04:31 (311 MB/s) - ‘metacritic-video-game-comments.zip’ saved [81214297/81214297]\n",
            "\n",
            "Archive:  metacritic-video-game-comments.zip\n",
            "  inflating: metacritic_game_info.csv  \n",
            "  inflating: metacritic_game_user_comments.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-w8L_AV46gqv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "f6c20308-4b22-481d-f3eb-71de468c45e5"
      },
      "cell_type": "code",
      "source": [
        "# Convert the data to a Pandas data frame\n",
        "comments = pd.read_csv('metacritic_game_user_comments.csv')\n",
        "# Shuffle with a fixed random seed\n",
        "comments = comments.sample(frac=1, random_state=387)\n",
        "comments = comments[pd.notnull(comments['Comment'])]\n",
        "comments.drop(['Unnamed: 0','Username'], axis=1, inplace=True)\n",
        "\n",
        "# Drop comments with less than 200 characters\n",
        "comments = comments[comments['Comment'].str.len() > 200]\n",
        "# Print the first 5 rows\n",
        "print(comments.count())\n",
        "print(comments.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title        225930\n",
            "Platform     225930\n",
            "Userscore    225930\n",
            "Comment      225930\n",
            "dtype: int64\n",
            "                              Title      Platform  Userscore  \\\n",
            "277924  Call of Duty: Black Ops III  PlayStation4          6   \n",
            "224106                      FIFA 18  PlayStation4          9   \n",
            "169926      Resistance: Fall of Man  PlayStation3          9   \n",
            "172446                    Titanfall       XboxOne          9   \n",
            "70980   Super Smash Bros. for Wii U          WiiU          9   \n",
            "\n",
            "                                                  Comment  \n",
            "277924  I liked it. But there is some downfalls. It ai...  \n",
            "224106  A welcomed evolution of  FIFA 17.Nothing seems...  \n",
            "169926   I'm generally a Noob when it comes to first-p...  \n",
            "172446  Wow, It is clear there is a lot of Sony fanboy...  \n",
            "70980   This is the best game in the series. Mostly ev...  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZpKjFb_f-WxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b9facacc-e0a4-4605-c1cb-e6e385dec018"
      },
      "cell_type": "code",
      "source": [
        "# Split data into train and test\n",
        "train_size = int(len(comments) * .8)\n",
        "print (\"Train size: %d\" % train_size)\n",
        "print (\"Test size: %d\" % (len(comments) - train_size))\n",
        "\n",
        "# Train features\n",
        "comments_train = comments['Comment'][:train_size]\n",
        "# Train labels\n",
        "labels_train = comments['Userscore'][:train_size]\n",
        "# Test features\n",
        "comments_test = comments['Comment'][train_size:]\n",
        "# Test labels\n",
        "labels_test = comments['Userscore'][train_size:]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 180744\n",
            "Test size: 45186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NThOL96A-vkb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a tokenizer to preprocess our text descriptions\n",
        "vocab_size = 12000 # This is a hyperparameter, experiment with different values for your dataset\n",
        "tokenize = keras.preprocessing.text.Tokenizer(num_words=vocab_size, char_level=False)\n",
        "tokenize.fit_on_texts(comments_train) # only fit on train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i4KPvNdaC0tY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "e6718fcd-c892-4230-a94d-1cbacf009c18"
      },
      "cell_type": "code",
      "source": [
        "# Define our wide model with the functional API\n",
        "bow_inputs = layers.Input(shape=(vocab_size,))\n",
        "inter = layers.Dense(64, activation='relu')(bow_inputs)\n",
        "predictions = layers.Dense(1)(inter)\n",
        "wide_model = keras.Model(inputs=bow_inputs, outputs=predictions)\n",
        "wide_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "print(wide_model.summary())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 12000)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                768064    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 768,129\n",
            "Trainable params: 768,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V0k7AEuk_IGC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d14efcee-c852-4bb1-939b-3852752fb84c"
      },
      "cell_type": "code",
      "source": [
        "max_seq_length = 2000\n",
        "\n",
        "# Define our deep model with the Functional API\n",
        "deep_inputs = layers.Input(shape=(max_seq_length,))\n",
        "embedding = layers.Embedding(vocab_size, 8, input_length=max_seq_length)(deep_inputs)\n",
        "embedding = layers.Flatten()(embedding)\n",
        "embedding = layers.Dense(64)(embedding)\n",
        "embedding = layers.Dropout(0.3)(embedding)\n",
        "embed_out = layers.Dense(1)(embedding)\n",
        "deep_model = keras.Model(inputs=deep_inputs, outputs=embed_out)\n",
        "deep_model.compile(loss='mse',\n",
        "                   optimizer='adam',\n",
        "                   metrics=['accuracy'])\n",
        "print(deep_model.summary())\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 2000)              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 2000, 8)           96000     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 16000)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                1024064   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,120,129\n",
            "Trainable params: 1,120,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0iTr2ynpGFwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "b35f3ff5-60a8-462c-8c25-da06cd1ebddf"
      },
      "cell_type": "code",
      "source": [
        "# Combine wide and deep into one model\n",
        "merged_out = layers.concatenate([wide_model.output, deep_model.output])\n",
        "merged_out = layers.Dense(64)(merged_out)\n",
        "merged_out = layers.Dropout(0.3)(merged_out)\n",
        "merged_out = layers.Dense(1)(merged_out)\n",
        "combined_model = keras.Model([wide_model.input, deep_model.input], merged_out)\n",
        "combined_model.compile(loss='mse',\n",
        "                       optimizer='adam',\n",
        "                       metrics=['accuracy'])\n",
        "print(combined_model.summary())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 2000)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 2000, 8)      96000       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 16000)        0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            (None, 12000)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 64)           1024064     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           768064      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            65          dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            65          dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 2)            0           dense_2[0][0]                    \n",
            "                                                                 dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 64)           192         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 64)           0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            65          dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,888,515\n",
            "Trainable params: 1,888,515\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7lPOuL7lXCLJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create the generator for fit and evaluate\n",
        "def generator(comments_list, labels_list, batch_size, tokenize, max_seq_length):\n",
        "    batch_number = 0\n",
        "    data_set_len = len(comments_list)\n",
        "    batches_per_epoch = int(data_set_len/batch_size)\n",
        "\n",
        "    while True:\n",
        "        initial = (batch_number*batch_size) % data_set_len\n",
        "        final = initial + batch_size\n",
        "        comments_to_send = comments_list[initial:final]\n",
        "\n",
        "        bow = tokenize.texts_to_matrix(comments_to_send)\n",
        "        embed = tokenize.texts_to_sequences(comments_to_send)\n",
        "        embed = keras.preprocessing.sequence.pad_sequences(\n",
        "            embed, maxlen=max_seq_length, padding=\"post\")\n",
        "\n",
        "        x = [bow, embed]\n",
        "        y = labels_list[initial:final]\n",
        "\n",
        "        batch_number = (batch_number+1) % batches_per_epoch\n",
        "        yield x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6pNmVr42HE1T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "74ec0e16-f3f5-4f1e-edea-3d69e91d52c3"
      },
      "cell_type": "code",
      "source": [
        "# Run training\n",
        "combined_model.fit_generator(\n",
        "    generator(comments_train, labels_train, 128, tokenize, max_seq_length),\n",
        "    steps_per_epoch=int(len(comments_train)/128),\n",
        "    epochs=7,\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "1412/1412 [==============================] - 161s 114ms/step - loss: 7.4596 - acc: 0.1708\n",
            "Epoch 2/7\n",
            "1412/1412 [==============================] - 164s 116ms/step - loss: 3.9296 - acc: 0.2305\n",
            "Epoch 3/7\n",
            "1412/1412 [==============================] - 160s 114ms/step - loss: 3.2566 - acc: 0.2594\n",
            "Epoch 4/7\n",
            "1412/1412 [==============================] - 160s 113ms/step - loss: 2.6895 - acc: 0.2812\n",
            "Epoch 5/7\n",
            "1412/1412 [==============================] - 159s 112ms/step - loss: 2.2005 - acc: 0.3062\n",
            "Epoch 6/7\n",
            "1412/1412 [==============================] - 159s 112ms/step - loss: 1.8291 - acc: 0.3309\n",
            "Epoch 7/7\n",
            "1412/1412 [==============================] - 158s 112ms/step - loss: 1.5765 - acc: 0.3499\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7ff1509db1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "gi4vBP-xHIuN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b40ecb81-9a1e-48e6-ea1c-f9b256944dd8"
      },
      "cell_type": "code",
      "source": [
        "print(combined_model.evaluate_generator(\n",
        "    generator(comments_test, labels_test, 128, tokenize, max_seq_length),\n",
        "    steps=int(len(comments_test)/128)\n",
        "))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.503198841813603, 0.28370662181303113]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CaIMTosfXfhd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c924ad87-9fd3-4ac0-f937-774950202c48"
      },
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "predictions = combined_model.predict_generator(\n",
        "    generator(comments_test, labels_test, 128, tokenize, max_seq_length),\n",
        "    steps=int(len(comments_test)/128)\n",
        ")\n",
        "\n",
        "# Compare predictions with actual values for the first few items in our test dataset\n",
        "diff = 0\n",
        "\n",
        "for i in range(len(predictions)):\n",
        "    val = predictions[i]\n",
        "    # print(description_test.iloc[i])\n",
        "    # print('Predicted: ', val[0], 'Actual: ', labels_test.iloc[i], '\\n')\n",
        "    diff += abs(val[0] - labels_test.iloc[i])\n",
        "\n",
        "# Compare the average difference between actual price and the model's predicted price\n",
        "print('Average prediction difference: ', diff / len(predictions))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average prediction difference:  1.4651924450077096\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}